{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3460b3",
   "metadata": {},
   "source": [
    "Seeting up the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d729f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in the environment variables.\")\n",
    "else:\n",
    "    print(\"OpenAI API key is set successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb34c6d",
   "metadata": {},
   "source": [
    "# OpenAI API Pricing Overview\n",
    "\n",
    "OpenAI offers several models with different pricing tiers based on performance and capabilities:\n",
    "\n",
    "## Main Models for Everyday Tasks\n",
    "\n",
    "### GPT-4.1 (Smartest model for complex tasks)\n",
    "- **Input**: $2.00 / 1M tokens\n",
    "- **Cached input**: $0.50 / 1M tokens  \n",
    "- **Output**: $8.00 / 1M tokens\n",
    "\n",
    "### GPT-4.1 mini (Affordable model balancing speed and intelligence)\n",
    "- **Input**: $0.40 / 1M tokens\n",
    "- **Cached input**: $0.10 / 1M tokens\n",
    "- **Output**: $1.60 / 1M tokens\n",
    "\n",
    "### GPT-4.1 nano (Fastest, most cost-effective for low-latency tasks)\n",
    "- **Input**: $0.100 / 1M tokens\n",
    "- **Cached input**: $0.025 / 1M tokens\n",
    "- **Output**: $0.400 / 1M tokens\n",
    "\n",
    "## Reasoning Models (for complex, multi-step problems)\n",
    "\n",
    "### OpenAI o3 (Most powerful reasoning model)\n",
    "- **Input**: $2.00 / 1M tokens\n",
    "- **Cached input**: $0.50 / 1M tokens\n",
    "- **Output**: $8.00 / 1M tokens\n",
    "\n",
    "### OpenAI o4-mini (Faster, cost-efficient reasoning model)\n",
    "- **Input**: $1.100 / 1M tokens\n",
    "- **Cached input**: $0.275 / 1M tokens\n",
    "- **Output**: $4.400 / 1M tokens\n",
    "\n",
    "## Cost Savings\n",
    "- **Batch API**: Save 50% on inputs and outputs for asynchronous tasks over 24 hours\n",
    "- **Cached inputs**: Significantly reduced pricing for repeated content\n",
    "\n",
    "## Additional APIs\n",
    "- **Realtime API**: For low-latency, multimodal experiences\n",
    "- **Image Generation**: Starting from ~$0.01 for low-quality square images\n",
    "- **Built-in tools**: Code Interpreter ($0.03), File Search ($0.10/GB/day), Web Search ($25/1K calls for GPT models)\n",
    "\n",
    "*Note: Prices are current as of the pricing page and may change. Always check the official OpenAI pricing page for the most up-to-date information.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d59b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client with the new v1.0+ syntax\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422f79d",
   "metadata": {},
   "source": [
    "# generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e769a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt,max_tokens=10, temperature=0.7):\n",
    "    # Using the new OpenAI API v1.0+ syntax with chat completions\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_completion_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fa9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time\"\n",
    "generated_text = generate_text(prompt, max_tokens=20, temperature=.2)\n",
    "print(f\"Generated text: {generated_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Engineer (Python)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
